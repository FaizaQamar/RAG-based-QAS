{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189b8651-7489-4cc7-b29c-570214128de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\.conda\\envs\\Umrah\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "import os\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import MultiRetrievalQAChain\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "import gradio as gr\n",
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7b7446-24b6-4cb5-81a5-a6de0690e71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c988b59-8e33-4ea4-bf9d-6fd68a71cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quran_db = FAISS.load_local('E:\\D\\Faiza\\PhD\\Thesis\\Implementation\\RAG based QAS\\RAG-based-QAS/Quran_db', embeddings, allow_dangerous_deserialization=True)\n",
    "behishti_db = FAISS.load_local('E:\\D\\Faiza\\PhD\\Thesis\\Implementation\\RAG based QAS\\RAG-based-QAS/behishti_db', embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f43a6d2-7cbd-419a-b4df-ac4112393705",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quran = Quran_db.as_retriever()\n",
    "Behishti = behishti_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ef4751-fc97-4878-a5f8-eb51a9e97d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_infos = [\n",
    "{\n",
    "\"name\": \"Quran\",\n",
    "\"description\": \"Good for answering general questions about Faith in Islam.\",\n",
    "\"retriever\": Quran\n",
    "},\n",
    "{\n",
    "\"name\": \"Behishti Zewar\",\n",
    "\"description\": \"Good for answering specific questions about daily life matters\",\n",
    "\"retriever\": Behishti\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f5fb9-19d0-4b5d-b737-f927b5b4c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b011dc9-b0ed-495c-9d70-de6dcf9ff471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\.conda\\envs\\Umrah\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a981b79-cc7e-46a9-8384-3ba728cca0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define your language model\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1024})\n",
    "\n",
    "# Define your retrievers\n",
    "retriever_infos = [\n",
    "    {\"name\": \"retriever1\", \"description\": \"Good for answering general questions about Faith in Islam.\", \"retriever\": Quran},\n",
    "    {\"name\": \"retriever2\", \"description\": \"Good for answering specific questions about daily life matters\", \"retriever\": Behishti}\n",
    "    # Add more retrievers as needed\n",
    "]\n",
    "\n",
    "# Define your default retriever and prompt\n",
    "default_retriever = BaseRetriever()\n",
    "template=\n",
    "default_prompt = PromptTemplate(template=\"Your default prompt template\", input_variables=[\"input\"])\n",
    "\n",
    "# Create the MultiRetrievalQAChain\n",
    "multi_retrieval_qa_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "    llm=llm,\n",
    "    retriever_infos=retriever_infos,\n",
    "    default_retriever=default_retriever,\n",
    "    default_prompt=default_prompt\n",
    ")\n",
    "\n",
    "# Use the chain\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": \"Your input\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21c6e9-1dbe-4b8b-a514-7b2470e107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "        You are a Muslim Scholar Assistant who helps Muslims with their queries related to their daily life matters with references to quran and ahadith.\n",
    "        If you don't know the answer to any question from the documents provided to you, then apologize.\n",
    "        Prepare your answer keeping in focus the Context and chat history of the user questions.\"\"\"\n",
    "B_INST, E_INST = \"<s>[INST] \", \" [/INST]\"\n",
    "template = (\n",
    "                B_INST\n",
    "                + system_prompt\n",
    "                + \"\"\"\n",
    "\n",
    "            Context: {context} / {chat_history}\n",
    "            User: {question}\"\"\"\n",
    "                + E_INST\n",
    "            )\n",
    "default_prompt = PromptTemplate(input_variables=[\"context\", \"chat_history\", \"question\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='Answer')\n",
    "#default_retriever = Quran_db.as_retriever()\n",
    "default_retriever = retreiver1\n",
    "default_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=default_retriever,\n",
    "    memory=memory,\n",
    "    return_generated_question=False,\n",
    "    rephrase_question=False,\n",
    "    return_source_documents=False,\n",
    "    combine_docs_chain_kwargs={\"prompt\": default_prompt}\n",
    "    )\n",
    "\n",
    "chain = MultiRetrievalQAChain.from_retrievers(llm, retriever_infos, default_prompt,default_chain=default_chain, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
